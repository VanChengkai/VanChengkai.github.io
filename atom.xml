<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Chengkai&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-07-27T14:02:14.257Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Chengkai</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Conversational Receommender Systems综述(一)</title>
    <link href="http://yoursite.com/2020/07/27/Conversational%20Recommender%20Systems%E7%BB%BC%E8%BF%B0/"/>
    <id>http://yoursite.com/2020/07/27/Conversational%20Recommender%20Systems%E7%BB%BC%E8%BF%B0/</id>
    <published>2020-07-27T13:32:29.000Z</published>
    <updated>2020-07-27T14:02:14.257Z</updated>
    
    <content type="html"><![CDATA[<p><img src="vanchengkai.github.io/images/15958542953009.jpg" alt="-w566"><br>近年来，推荐系统的各项子课题接连出现，而对话式的推荐系统也成为了一个新兴的子课题。<br>In recent years, the emerging topics of recommender systems that take advantage of natural language processing techniques have attracted much attention, and one of their applications is the Conversational Recommender System (CRS).</p><a id="more"></a><h2 id="1-Background-and-Definition"><a href="#1-Background-and-Definition" class="headerlink" title="1.Background and Definition"></a>1.Background and Definition</h2><p>文章对对话式推荐系统进行了定义：Unlike traditional recommender systems with content-based and collaborative filtering approaches, CRS learns and models user’s preferences through interactive dialogue conversations. </p><p>众所周知，两种主流的推荐系统框架是conten-based的基于内容的推荐系统，或者CF协同过滤的推荐系统，CRS主要是通过与客户对话来学习到用户对物品的偏好。而这篇2020年的来自澳洲的综述，主要讨论的是基于DL方法的对话推荐系统。</p><p>对DL-based的对话推荐系统，作者们是这样定义的：Nevertheless, we are seeing a recent trend in the field of CRS, where deep learning approaches are being used to provide end-to-end solutions for CRS, and these systems are considered as Deep Conversational Recommender Systems (DCRS).并给出了如下图的说明过程：<br><img src="vanchengkai.github.io/images/15958542216380.jpg" alt=""><br>上图是对话机器人的示例。Here we use the term users to denote the information seekers, and the term agents to denote the information providers：上图的用户是信息的seeker, 而机器人是信息的提供者。</p><p>From the perspective of online businesses, due to the natural and personal characteristics of direct communication via conversations, a large amount of modern services provide call or chat systems to deal with customer support. However, human resources are limited and costly, thus, the need of intelligent agents who are able to converse with users and give satisfactory recommendations is essential to them. 说明推荐在chat systems中的重要性，On the other hand, from the user’s perspective, the ability to freely express one’s preferences and retrieve tailored suggestions from the agents give the users a strong sense of satisfaction and confidence in the choices they make.</p><p><strong>* 分割线 *</strong></p><h2 id="2-Main-Components-and-Challenges"><a href="#2-Main-Components-and-Challenges" class="headerlink" title="2.Main Components and Challenges"></a>2.Main Components and Challenges</h2><h3 id="2-1-Components"><a href="#2-1-Components" class="headerlink" title="2.1 Components"></a>2.1 Components</h3><p>以上主要是对背景和研究意义的说明和介绍，然后作者引出了DCRS的主要组件：<br><img src="vanchengkai.github.io/images/15958546812312.jpg" alt=""><br>这个图非常的清晰： DCRS的组件：In a typical CRS, there exists three components, a User Intention Understanding (UIU) module, a Recommendation (REC) module, and a Switching Mechanism (SWM).<br>典型的对话推荐系统一般包括三个模块：用户意图理解模块UIU、推荐模块REC和选择模块SWM。</p><p>UIU模块用于从用户输入和系统响应中挖掘用户偏好，确定当前的对话状态，这里的用户输入可能是多模态的，如文本、图片等。SWM模块是根据当前的对话状态决定继续问用户问题还是直接根据当前的用户偏好进行推荐。在一些场景中，SWM要同时根据UIU模块和REC模块的信号进行决策。此外，有研究通过引入改进模块IM处理基于用户反馈的推荐。作者将这几个模块中至少有一个模块应用深度学习方法的对话推荐系统称为深度对话推荐系统DCRS。</p><p>DCRS is primarily a goal-oriented dialogue system which also incorporates the element of chit-chat and question answering dialogue systems所以DCRS就是一个集闲聊与问答的对话系统。This natural mode of interaction between users and agents presents considerable challenges when designing such a system. 用户和系统之间的自然交互模式是最大的挑战。</p><p>If the user initiates new request after that, a new round starts. A multi-round DCRS is a system where after each round, the agent can improve its recommendation outputs based on the learned user’s preferences from previous round. Some DCRS accept user’s feedback at the end of a round. A user’s feedback is usually a positive or negative confirmation utterance言论 after the agent’s recommendation output. </p><h3 id="2-2-Challenges"><a href="#2-2-Challenges" class="headerlink" title="2.2 Challenges"></a>2.2 Challenges</h3><p>作者这里指出了两个主要的挑战：</p><ul><li>理解用户意图 UIU </li><li>给出合适的recommendations，也就是个性化推荐</li></ul><p>对于第一点,原文是这样说的：It is critical for the agent to know what is the current user’s intention for the system to act. However, text understanding and comprehension is a complicated ongoing research in the field of deep learning. 文本语义理解本身就是一个很难的问题。因此，对于NLU部分：自然语言理解，作者说明主流的方法有两种：</p><ul><li>The first group, which is typically used by DCRS that are trained on synthetic dataset, is attributes extraction from user’s utterances. 在语义训练集上进行训练。</li><li>The second group tries to encode the whole dialogue utterances via RNN-based neural network to extract a dialogue state直接使用RNN来编码。<br>个人理解，这里的工作其实有一些复杂，写的两种方法看起来过于理想。具体来说，在实际的dialogue systems当中，一般这块的数据是要用slot额外标注的，具体要标注出意图(intent)和实体(entity)，就以Sara这种工程类的开源对话系统来讲，要针对一个具体的domain进行数据标注才会有较好的效果，一般以json的形式来记录对话中，用户每句话的意图。另外，多domain的对话系统可以参照清华和微软做的convlab-2。</li></ul><p>对于第二点，个性化推荐：However, certain DCRS are designed to act more like a search-and-filter engines, that only consider user’s preferences in the current dialogue session.传统的推荐都会存在冷启动的问题，对话推荐也不例外，所以：<br>To overcome this issue of lacking personalized recommendations in the system, the DCRS needs to know the user’s features (age, gender, etc.)要克服这类的问题：需要用户的个人信息，例如性别年龄等等-&gt;user profile。</p><h2 id="2-3-SWM的过程"><a href="#2-3-SWM的过程" class="headerlink" title="2.3 SWM的过程"></a>2.3 SWM的过程</h2><p>本小节的最后，谈一下SWM的过程：It is imperative紧要的，重要的 for a DCRS to know when to ask questions to learn more about user’s preferences, or when to give responses with recommendation results.<br>对话系统如何选择询问的问题和何时进行有效的推荐都是很重要的问题。如果更进一步的说，其实还需要考虑什么时候结束会话，这一个step其实和NLU紧密相关，并且近年来还有Multi-modal的对话需求，也需要对visual cue进行理解，这个都是很困难的问题。</p><p>综述中给出了三种主流的方法：选择模块：一共有三种方法rule-based，pointer softmax and RL。<br>基于规则的方法、指针softmax和强化学习的方法。</p><ul><li>For rule-based SWM, there is no specific methodology. A rule can be just a simple constraint, such as for each turn, always providing a recommendation [Christakopoulou et al., 2018], or a designed choice such as the confident score of the top-k recommended items over a threshold [Zhang et al., 2018].第一种，没有什么特别的，写一个死规则，例如：每轮都进行推荐</li><li>第二种：Pointer softmax probability is originated from [Gulc¸ehreet al., 2016], where SWM uses the Gated Recurrent Unit (GRU) cell to decode hidden state of the current dialogue context, and decides whether to generate response tokens with or without recommended item via a softmax probability score, which leads to natural and fluent agent’s generative responses as seen in the works of [Li et al., 2018; Liao et al., 2019]. 用GRU编码之后，输出一个预测概率来决定是否要进行recommend的行为。</li><li>The third approach is reinforcement policy score, where at each turn in a dialogue session, SWM generates an action vector based on embedding signals from UIU and REC modules. 最后就是现在很火的强化学习方法。This action vector then is fed into a reinforcement policy network强化策略网络, and outputs a softmax class score to reflect which action to take. Henceforth, the policy network is trained to maximize the action reward based on the labels of the dataset. This SWM approach is chosen by the works that focus on generating mechanical responses.<br>本篇博文就先总结到这里，就酱(引用之后再补。)~</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;vanchengkai.github.io/images/15958542953009.jpg&quot; alt=&quot;-w566&quot;&gt;&lt;br&gt;近年来，推荐系统的各项子课题接连出现，而对话式的推荐系统也成为了一个新兴的子课题。&lt;br&gt;In recent years, the emerging topics of recommender systems that take advantage of natural language processing techniques have attracted much attention, and one of their applications is the Conversational Recommender System (CRS).&lt;/p&gt;
    
    </summary>
    
    
      <category term="对话系统，推荐系统" scheme="http://yoursite.com/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F%EF%BC%8C%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
  </entry>
  
  <entry>
    <title>Reinforcement Learning 港中文课程（一）</title>
    <link href="http://yoursite.com/2020/05/26/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E2%80%94%E6%B8%AF%E4%B8%AD%E6%96%87%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0(%E4%B8%80)/"/>
    <id>http://yoursite.com/2020/05/26/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E2%80%94%E6%B8%AF%E4%B8%AD%E6%96%87%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0(%E4%B8%80)/</id>
    <published>2020-05-26T10:10:29.000Z</published>
    <updated>2020-07-27T13:33:42.699Z</updated>
    
    <content type="html"><![CDATA[<p>今天开始学习港中文周博磊的强化学习课程。记录一些相关的内容，希望别荒废了。</p><a id="more"></a><p><a href="https://github.com/zhoubolei/introRL" target="_blank" rel="noopener">课程GitHub</a></p><p>强化学习:</p><p>select a series of actions to maximize total future rewards</p><ol><li><p>actions may have long term consequences</p></li><li><p>reward may be delay</p></li><li><p>trade-off between immediate reward and long-term reward</p><p>（短时间奖励和长时间奖励）</p><p>与 环境交互的过程 Observations, actions, rewards</p></li></ol><p>环境 full observability / partial observability</p><p>Black Jack 只能看见公牌， Atari只能看到pixel</p><p>Major Components of an RL Agent:</p><p>agent的组成元素： </p><ol><li>Policy 是agent的行为函数，也就是决定agent下一步的动作或者动作分布。</li><li>Value function：how good is each state or action用来说明动作的优劣</li><li>Model: 代表是agent对这个环境的理解，决定整个世界是怎么进行的</li></ol><p>Policy:  is the agent’s behavior model是agent的行为模型</p><p>map function from state/observation to action.</p><p>1.随机stochastic policy：<br>$$<br>π(a|s)=P[A_t=a|S_t=s]<br>$$<br>输入一个状态s，输出一个概率，然后对这个概率分布进行采样，产生新的动作。</p><ol start="2"><li>Deterministic policy：</li></ol><p>公式<br>$$<br>a^*=argmax_aπ(a|s)<br>$$<br>第二种是确定性Policy 采取极大化，采取最有可能的动作</p><p>雅达利打砖块的游戏的动作就是决定向左还是向右移动。</p><p>Value Function:价值函数</p><p>expected discounted sum of future rewards under a particular policy π</p><p>一个折扣的未来奖励的加和</p><p>discount factor weights vs future rewards</p><p>折合因子</p><p>Model: 模型决定了下一个状态的动作</p><p>马尔科夫决策过程： MDPs</p><p>agents：基于价值函数的agent 隐式</p><p>policy-based agent</p><p>actor-critic agent 两种都学习了</p><p>agent是否学习了环境模型</p><p>model-based 直接考虑了环境的状态的转移</p><p>model-free</p><p>exploration 怎么探索环境 试错</p><p>exploitation 不去探索 只采取最好的行为</p><p>trade-off        </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天开始学习港中文周博磊的强化学习课程。记录一些相关的内容，希望别荒废了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="强化学习" scheme="http://yoursite.com/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>Beyond the Product-Discovering Image Posts for Brands in Social Media论文与代码解读</title>
    <link href="http://yoursite.com/2020/05/07/PCD%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B/"/>
    <id>http://yoursite.com/2020/05/07/PCD%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B/</id>
    <published>2020-05-07T03:32:29.000Z</published>
    <updated>2020-07-27T14:01:16.298Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://vanchengkai.github.io/images/image-20200507113351640.png" alt="image-20200507113351640"></p><p>本篇工作的背景是面向品牌方，目标是在社交平台中挖掘出合适的UGC内容（就是用户在社交平台上发布的posts），这类内容要符合品牌商的品牌理念（或者包含相关的内容）。</p><a id="more"></a><p><img src="https://vanchengkai.github.io/images/image-20200507113314084.png" alt="image-20200507113314084"></p><h4 id="论文部分："><a href="#论文部分：" class="headerlink" title="论文部分："></a>论文部分：</h4><p>1.数据集：是从Instagram上爬取的900个左右的品牌最近发布的1000个左右的posts，图片或者是视频，视频主要通过抽帧（一个视频好像是抽三帧）来构造的。</p><p>2.模型部分：模型部分并不复杂，右边是图片的输入，图片分为正样本和负样本，左边是品牌表示学习brand representation learning, 就是用nn.Embedding把brand_id升维然后构造一个矩阵A，然后通过一系列的复制，维度对齐操作，得到一个与右边图片可以做矩阵乘法的表示，然后用一个MarginRankingLoss来约束distance(品牌表示，正样本)&lt;distance(品牌表示， 负样本)。</p><h4 id="代码部分"><a href="#代码部分" class="headerlink" title="代码部分"></a>代码部分</h4><p>主要是自己做一个总结，写的比较乱。</p><p>一.特征提取</p><p>这里我是更换了一个汽车品牌的细粒度数据集：    </p><p>先单独运行extract_visual_feature.py文件，用vgg16_bn去提取品牌数据集的图片特征，（这里为了对比实验）之后换成了vgg19_bn，其他网络结构同理，只要求图片特征维度最后出来是4096。最后会拿到一个特征矩阵feature_matrix（98169 x 4096）第一个是汽车数据集的样本数，第二维是图片特征。存成npy文件。</p><p>然后这里需要挑选出正样本和负样本的pair:</p><p>we randomly sampled ten negative sample posts.</p><p>原论文中是一个正样本，去提取10个负样本。</p><p>这类我们增加了负样本的量，性能会有所提高.</p><p>二.训练</p><p>train.py</p><p>主要看train这个函数：</p><p>先看使用的损失函数是Margin_ranking_loss:</p><p>torch.nn.MarginRankingLoss(margin=0.0, reduction=’mean’) </p><p>对于 mini-batch 中每个实例的损失函数如下:</p><p><img src="https://vanchengkai.github.io/images/20181230222507854.png" alt="在这里插入图片描述"></p><p>y是标签， x1正样本，x2负样本：</p><p>loss = loss_function(out_pos, out_neg, ones)</p><p>out_pos  图像输出的正样本特征</p><p>out_neg 图像输出的负样本特征</p><p>ones  是硬标签</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ones = torch.ones(image_pos.size()[<span class="number">0</span>], <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>[256(batch_size),1]</p><p>这里margin是超参数，取了0.3</p><p><img src="https://vanchengkai.github.io/images/image-20200418101709713.png" alt="image-20200418101709713"></p><p>官方文档写的很清楚了 取1的情况就是希望这两个样本之间的距离越大越好。</p><p>三.模型</p><p>模型这部分有点复杂</p><p>先看VggModel()</p><p>我们把他给打印出来：</p><p><img src="/https://vanchengkai.github.io/images/image-20200418102904409.png" alt="image-20200418102904409"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out_pos = model(&#123;<span class="string">'image'</span>: image_pos, <span class="string">'brand'</span>: brand&#125;)</span><br><span class="line">out_neg = model(&#123;<span class="string">'image'</span>: image_neg, <span class="string">'brand'</span>: brand&#125;)</span><br></pre></td></tr></table></figure><p>注意这个模型的输入有两个：</p><p>一个是图像的特征输入，一个是品牌的index（0…50）</p><p>然后我们看VggModel的forward()函数</p><p>先是简单的两层MLP 把图像特征4096-&gt;4096-&gt;1024中间使用leaky relu连接的</p><p>然后我们看输入的品牌index:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.brand_embeddings = nn.Embedding(num_brands, self.num_aspects)`</span><br></pre></td></tr></table></figure><p>nn.Embedding这个函数其实就是生成词向量用的：</p><p>第一个维度是词的个数，第二个参数是生成词向量的维度</p><p>这里j就是这届把品牌id(index形式)输入进去了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brand_weights = self.brand_embeddings(data[<span class="string">'brand'</span>])</span><br></pre></td></tr></table></figure><p>所以这里输出的weights输出就是2000维的品牌表示：</p><p>L1Penalty.apply(brand_weights)这里加了一个L1惩罚</p><p>目的是为了实现稀疏性（使中间层一定比例的系数为0）</p><p>接下来就是最关键的代码了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w_aspects = torch.mul(brand_weights.view(im_ft.shape[<span class="number">0</span>], self.num_aspects, <span class="number">1</span>).expand(im_ft.shape[<span class="number">0</span>], self.num_aspects, im_ft.shape[<span class="number">1</span>]), self.aspects_embeddings.view(<span class="number">1</span>, self.num_aspects, im_ft.shape[<span class="number">1</span>]).expand(im_ft.shape[<span class="number">0</span>], self.num_aspects, im_ft.shape[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><p>一点点分析：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brand_weights.view(im_ft.shape[<span class="number">0</span>], self.num_aspects, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>brand_weight输出是2000维度</p><p>im_ft.shape[0] 是batchsize</p><p>就是展成[256,2000,1]的格式</p><p>.expand(im_ft.shape[0], self.num_aspects, im_ft.shape[1])</p><p>[256,2000,1024]</p><p>就是复制</p><p>[256,2000,1]</p><p>[256,2000,1024]</p><p>看第二项</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.aspects_embeddings.view(<span class="number">1</span>, self.num_aspects, im_ft.shape[<span class="number">1</span>]).expand(im_ft.shape[<span class="number">0</span>], self.num_aspects, im_ft.shape[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><p>首先：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.aspects_embeddings = nn.Parameter(torch.randn(self.num_aspects, self.embedding_size), requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>nn.Parameter这玩意就是把不可训练的Tensor弄成可训练的，并绑定到module里</p><p>[2000, 1024]</p><p>一样的操作：</p><p>[1,2000,1024] -&gt; [256,2000,1024]</p><p>torch.mul 逐元素点乘</p><p>结果[256,2000,1024]</p><p>最后  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prod = torch.bmm(w_aspects, im_ft.view(im_ft.shape[<span class="number">0</span>], im_ft.shape[<span class="number">1</span>], <span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>[256,2000,1024]    [256,1024,1]</p><p>bmm操作：</p><p>tensor a 的size为(a,b,c),tensor b的size为(a,c,d).</p><p>结果为(a,b,d)</p><p>[256,2000,1]</p><p>prod dropout之后 就是一个mean均值变成1维度</p><p>然后通过margin_ranking_loss训练</p><p>![image-20200418232705723](/Users/hck/Library/Application Support/typora-user-images/image-20200418232705723.png)</p><p>最后就走完了这个流程：</p><p>实际把A的计算换成一个标准的全连接层加上relu似乎不影响在我数据集上的性能。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://vanchengkai.github.io/images/image-20200507113351640.png&quot; alt=&quot;image-20200507113351640&quot;&gt;&lt;/p&gt;
&lt;p&gt;本篇工作的背景是面向品牌方，目标是在社交平台中挖掘出合适的UGC内容（就是用户在社交平台上发布的posts），这类内容要符合品牌商的品牌理念（或者包含相关的内容）。&lt;/p&gt;
    
    </summary>
    
    
      <category term="品牌推广，推荐系统" scheme="http://yoursite.com/categories/%E5%93%81%E7%89%8C%E6%8E%A8%E5%B9%BF%EF%BC%8C%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
  </entry>
  
  <entry>
    <title>Leduk规则说明</title>
    <link href="http://yoursite.com/2020/03/19/Leduk%E8%A7%84%E5%88%99%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2020/03/19/Leduk%E8%A7%84%E5%88%99%E4%BB%8B%E7%BB%8D/</id>
    <published>2020-03-19T10:10:29.000Z</published>
    <updated>2020-03-19T10:10:48.164Z</updated>
    
    <content type="html"><![CDATA[<p>Leduc Hold’em is a toy poker game sometimes used in academic research(first introduced in <a href="http://poker.cs.ualberta.ca/publications/UAI05.pdf" target="_blank" rel="noopener">Bayes’ Bluff: Opponent Modeling in Poker</a>). </p><p>简单来说，Leduk就是简化的德州扑克游戏。他的全称是heads-up no-limit Leduk，即单挑无限注扑克游戏。 </p><a id="more"></a><p>It is played with a deck of six cards, comprising two suits of three ranks each (often the king, queen, and jack - in our implementation, the ace, king, and queen). The game begins with each player being dealt one card privately, followed by a betting round. Then, another card is dealt faceup as a community (or board) card, and there is another betting round. Finally, the players reveal their private cards. If one player’s private card is the same rank as the board card, he or she wins the game; otherwise, the player whose private card has the higher rank wins.</p><p>这个游戏经常用于学术研究中，一副牌有六张：有两套三个等级的卡片：国王、王后和杰克。游戏开始后，每个玩家会获得一张私牌，然后进行一轮下注。之后，再讲另一张牌作为公牌放在桌面上，进行另一轮下注。最后，玩家展示他们的私牌，若一个玩家的私牌和公牌相同，他（她）获胜（因为每种牌只有两张，这里就不会平局）；否则，私牌牌面更高的玩家获胜。</p><p>The game that we implement is No-Limit Leduc Hold’em, meaning that whenever a player makes a bet, he or she may wager any amount of chips up to a maximum of that player’s remaining stack. There is also no limit on the number of bets and raises that can be made in each betting round.</p><p>这个游戏是无限注德州扑克，这意味着每当玩家下注时，他或她都可以下注任何数量的筹码，直到该玩家剩余筹码的最大值。 每一轮下注和加注的次数也没有限制。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Leduc Hold’em is a toy poker game sometimes used in academic research(first introduced in &lt;a href=&quot;http://poker.cs.ualberta.ca/publications/UAI05.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Bayes’ Bluff: Opponent Modeling in Poker&lt;/a&gt;). &lt;/p&gt;
&lt;p&gt;简单来说，Leduk就是简化的德州扑克游戏。他的全称是heads-up no-limit Leduk，即单挑无限注扑克游戏。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="德州扑克" scheme="http://yoursite.com/categories/%E5%BE%B7%E5%B7%9E%E6%89%91%E5%85%8B/"/>
    
    
  </entry>
  
  <entry>
    <title>Torch框架学习（一）</title>
    <link href="http://yoursite.com/2020/03/19/torch%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://yoursite.com/2020/03/19/torch%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89/</id>
    <published>2020-03-19T10:10:29.000Z</published>
    <updated>2020-05-26T13:40:33.458Z</updated>
    
    <content type="html"><![CDATA[<p>Torch is a scientific computing framework with wide support for machine learning algorithms that puts GPUs first. It is easy to use and efficient, thanks to an easy and fast scripting language, LuaJIT, and an underlying C/CUDA implementation.</p><p>Torch是一个可用于深度学习的计算框架，支持GPU；得益于简单快速的脚本语言，LuaJIT和底层C / CUDA实现，它易于使用且高效。</p><a id="more"></a><p>The goal of Torch is to have maximum flexibility and speed in building your scientific algorithms while making the process extremely simple. Torch comes with a large ecosystem of community-driven packages in machine learning, computer vision, signal processing, parallel processing, image, video, audio and networking among others, and builds on top of the Lua community.</p><p>At the heart of Torch are the popular neural network and optimization libraries which are simple to use, while having maximum flexibility in implementing complex neural network topologies. You can build arbitrary graphs of neural networks, and parallelize them over CPUs and GPUs in an efficient manner.</p><p>Torch基于lua社区，其核心是易于使用的流行神经网络库和优化库，并且易于并行。</p><p>简单地介绍一下Lua: Because Torch is based on Lua and runs on Lua-JIT(just-in-time complier) which is fast.</p><ul><li><p>Lua is pretty close to javascript.</p></li><li><p>Only has one data structure built-in, a table: <code>{}</code>. Doubles as a hash-table and an array. 只有一种内置的数据结构</p></li><li><p>1-based indexing.</p><p>这里说明一下循环的写法，和python有些不一样： –代表注释</p><p>#(*) 代表长度</p></li></ul><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i=<span class="number">1</span>,#b <span class="keyword">do</span> <span class="comment">-- the # operator is the length operator in Lua</span></span><br><span class="line">    <span class="built_in">print</span>(b[i]) </span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>关于torch如何构造张量Tensor</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Torch is a scientific computing framework with wide support for machine learning algorithms that puts GPUs first. It is easy to use and efficient, thanks to an easy and fast scripting language, LuaJIT, and an underlying C/CUDA implementation.&lt;/p&gt;
&lt;p&gt;Torch是一个可用于深度学习的计算框架，支持GPU；得益于简单快速的脚本语言，LuaJIT和底层C / CUDA实现，它易于使用且高效。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Torch" scheme="http://yoursite.com/categories/Torch/"/>
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2020/03/19/hello-world/"/>
    <id>http://yoursite.com/2020/03/19/hello-world/</id>
    <published>2020-03-19T02:38:08.159Z</published>
    <updated>2020-03-19T02:38:08.159Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
