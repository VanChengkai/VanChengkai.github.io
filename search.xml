<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>PCD算法流程</title>
    <url>/2020/04/18/PCD%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<p>title: Beyond the Product: Discovering Image Posts for Brands in Social Media论文与代码解读</p>
<p>date: 2020-05-07 11:32:29<br>categories: 品牌推广，推荐系统<br>toc: true  </p>
<p>![image-20200507113351640](/Users/hck/Library/Application Support/typora-user-images/image-20200507113351640.png)</p>
<p>本篇工作的背景是面向品牌方，目标是在社交平台中挖掘出合适的UGC内容（就是用户在社交平台上发布的posts），这类内容要符合品牌商的品牌理念（或者包含相关的内容）。</p>
<p>![image-20200507113314084](/Users/hck/Library/Application Support/typora-user-images/image-20200507113314084.png)</p>
<h4 id="论文部分："><a href="#论文部分：" class="headerlink" title="论文部分："></a>论文部分：</h4><p>1.数据集：是从Instagram上爬取的900个左右的品牌最近发布的1000个左右的posts，图片或者是视频，视频主要通过抽帧（一个视频好像是抽三帧）来构造的。</p>
<p>2.模型部分：模型部分并不复杂，右边是图片的输入，图片分为正样本和负样本，左边是品牌表示学习brand representation learning, 就是用nn.Embedding把brand_id升维然后构造一个矩阵A，然后通过一系列的复制，维度对齐操作，得到一个与右边图片可以做矩阵乘法的表示，然后用一个MarginRankingLoss来约束distance(品牌表示，正样本)&lt;distance(品牌表示， 负样本)。</p>
<h4 id="代码部分"><a href="#代码部分" class="headerlink" title="代码部分"></a>代码部分</h4><p>一.特征提取</p>
<p>这里我是更换了一个汽车品牌的细粒度数据集：    </p>
<p>先单独运行extract_visual_feature.py文件，用vgg16_bn去提取品牌数据集的图片特征，（这里为了对比实验）之后换成了vgg19_bn，其他网络结构同理，只要求图片特征维度最后出来是4096。最后会拿到一个特征矩阵feature_matrix（98169 x 4096）第一个是汽车数据集的样本数，第二维是图片特征。存成npy文件。</p>
<p>然后这里需要挑选出正样本和负样本的pair:</p>
<p>we randomly sampled ten negative sample posts.</p>
<p>原论文中是一个正样本，去提取10个负样本。</p>
<p>这类我们增加了负样本的量，性能会有所提高</p>
<p>二.训练</p>
<p>train.py</p>
<p>主要看train这个函数：</p>
<p>先看使用的损失函数是Margin_ranking_loss:</p>
<p>torch.nn.MarginRankingLoss(margin=0.0, reduction=’mean’) </p>
<p>对于 mini-batch 中每个实例的损失函数如下:</p>
<p><img src="https://img-blog.csdnimg.cn/20181230222507854.png" alt="在这里插入图片描述"></p>
<p>y是标签， x1正样本，x2负样本：</p>
<p>loss = loss_function(out_pos, out_neg, ones)</p>
<p>out_pos  图像输出的正样本特征</p>
<p>out_neg 图像输出的负样本特征</p>
<p>ones  是硬标签</p>
<p>ones = torch.ones(image_pos.size()[0], 1)</p>
<p>[256(batch_size),1]</p>
<p>这里margin是超参数，取了0.3</p>
<p>![image-20200418101709713](/Users/hck/Library/Application Support/typora-user-images/image-20200418101709713.png)</p>
<p>官方文档写的很清楚了 取1的情况就是希望这两个样本之间的距离越大越好。</p>
<p>三.模型</p>
<p>模型这部分有点复杂</p>
<p>先看VggModel()</p>
<p>我们把他给打印出来：</p>
<p>![image-20200418102904409](/Users/hck/Library/Application Support/typora-user-images/image-20200418102904409.png)</p>
<p> out_pos = model({‘image’: image_pos, ‘brand’: brand})</p>
<p> out_neg = model({‘image’: image_neg, ‘brand’: brand})</p>
<p>注意这个模型的输入有两个：</p>
<p>一个是图像的特征输入，一个是品牌的index（0…50）</p>
<p>然后我们看VggModel的forward()函数</p>
<p>先是简单的两层MLP 把图像特征4096-&gt;4096-&gt;1024中间使用leaky relu连接的</p>
<p>然后我们看输入的品牌index:</p>
<p>self.brand_embeddings = nn.Embedding(num_brands, self.num_aspects)</p>
<p>nn.Embedding这个函数其实就是生成词向量用的：</p>
<p>第一个维度是词的个数，第二个参数是生成词向量的维度</p>
<p>这里j就是这届把品牌id(index形式)输入进去了：</p>
<p>brand_weights = self.brand_embeddings(data[‘brand’])</p>
<p>所以这里输出的weights输出就是2000维的品牌表示：</p>
<p>L1Penalty.apply(brand_weights)这里加了一个L1惩罚</p>
<p>目的是为了实现稀疏性（使中间层一定比例的系数为0）</p>
<p>接下来就是最关键的代码了：</p>
<p>w_aspects = torch.mul(brand_weights.view(im_ft.shape[0], self.num_aspects, 1).expand(im_ft.shape[0], self.num_aspects, im_ft.shape[1]), self.aspects_embeddings.view(1, self.num_aspects, im_ft.shape[1]).expand(im_ft.shape[0], self.num_aspects, im_ft.shape[1]))   </p>
<p>一点点分析：</p>
<p>brand_weights.view(im_ft.shape[0], self.num_aspects, 1)</p>
<p>brand_weight输出是2000维度</p>
<p>im_ft.shape[0] 是batchsize</p>
<p>就是展成[256,2000,1]的格式</p>
<p>.expand(im_ft.shape[0], self.num_aspects, im_ft.shape[1])</p>
<p>[256,2000,1024]</p>
<p>就是复制</p>
<p>[256,2000,1]</p>
<p>[256,2000,1024]</p>
<p>看第二项</p>
<p>self.aspects_embeddings.view(1, self.num_aspects, im_ft.shape[1]).expand(im_ft.shape[0], self.num_aspects, im_ft.shape[1]))</p>
<p>首先：</p>
<p> self.aspects_embeddings = nn.Parameter(torch.randn(self.num_aspects, self.embedding_size), requires_grad=True)</p>
<p>nn.Parameter这玩意就是把不可训练的Tensor弄成可训练的，并绑定到module里</p>
<p>[2000, 1024]</p>
<p>一样的操作：</p>
<p>[1,2000,1024] -&gt; [256,2000,1024]</p>
<p>torch.mul 逐元素点乘</p>
<p>结果[256,2000,1024]</p>
<p>最后  </p>
<p>prod = torch.bmm(w_aspects, im_ft.view(im_ft.shape[0], im_ft.shape[1], 1))</p>
<p>[256,2000,1024]    [256,1024,1]</p>
<p>bmm操作：</p>
<p>tensor a 的size为(a,b,c),tensor b的size为(a,c,d).</p>
<p>结果为(a,b,d)</p>
<p>[256,2000,1]</p>
<p>prod dropout之后 就是一个mean均值变成1维度</p>
<p>然后通过margin_ranking_loss训练</p>
<p>![image-20200418232705723](/Users/hck/Library/Application Support/typora-user-images/image-20200418232705723.png)</p>
<p>最后就走完了这个流程：</p>
<p>实际把A的计算换成一个标准的全连接层加上relu似乎不影响在我数据集上的性能。</p>
]]></content>
  </entry>
  <entry>
    <title>Leduk规则说明</title>
    <url>/2020/03/19/Leduk%E8%A7%84%E5%88%99%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<p>Leduc Hold’em is a toy poker game sometimes used in academic research(first introduced in <a href="http://poker.cs.ualberta.ca/publications/UAI05.pdf" target="_blank" rel="noopener">Bayes’ Bluff: Opponent Modeling in Poker</a>). </p>
<p>简单来说，Leduk就是简化的德州扑克游戏。他的全称是heads-up no-limit Leduk，即单挑无限注扑克游戏。 </p>
<a id="more"></a>

<p>It is played with a deck of six cards, comprising two suits of three ranks each (often the king, queen, and jack - in our implementation, the ace, king, and queen). The game begins with each player being dealt one card privately, followed by a betting round. Then, another card is dealt faceup as a community (or board) card, and there is another betting round. Finally, the players reveal their private cards. If one player’s private card is the same rank as the board card, he or she wins the game; otherwise, the player whose private card has the higher rank wins.</p>
<p>这个游戏经常用于学术研究中，一副牌有六张：有两套三个等级的卡片：国王、王后和杰克。游戏开始后，每个玩家会获得一张私牌，然后进行一轮下注。之后，再讲另一张牌作为公牌放在桌面上，进行另一轮下注。最后，玩家展示他们的私牌，若一个玩家的私牌和公牌相同，他（她）获胜（因为每种牌只有两张，这里就不会平局）；否则，私牌牌面更高的玩家获胜。</p>
<p>The game that we implement is No-Limit Leduc Hold’em, meaning that whenever a player makes a bet, he or she may wager any amount of chips up to a maximum of that player’s remaining stack. There is also no limit on the number of bets and raises that can be made in each betting round.</p>
<p>这个游戏是无限注德州扑克，这意味着每当玩家下注时，他或她都可以下注任何数量的筹码，直到该玩家剩余筹码的最大值。 每一轮下注和加注的次数也没有限制。</p>
]]></content>
      <categories>
        <category>德州扑克</category>
      </categories>
  </entry>
  <entry>
    <title>Torch框架学习（一）</title>
    <url>/2020/03/19/torch%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>Torch is a scientific computing framework with wide support for machine learning algorithms that puts GPUs first. It is easy to use and efficient, thanks to an easy and fast scripting language, LuaJIT, and an underlying C/CUDA implementation.</p>
<p>Torch是一个可用于深度学习的计算框架，支持GPU；得益于简单快速的脚本语言，LuaJIT和底层C / CUDA实现，它易于使用且高效。</p>
<a id="more"></a>

<p>The goal of Torch is to have maximum flexibility and speed in building your scientific algorithms while making the process extremely simple. Torch comes with a large ecosystem of community-driven packages in machine learning, computer vision, signal processing, parallel processing, image, video, audio and networking among others, and builds on top of the Lua community.</p>
<p>At the heart of Torch are the popular neural network and optimization libraries which are simple to use, while having maximum flexibility in implementing complex neural network topologies. You can build arbitrary graphs of neural networks, and parallelize them over CPUs and GPUs in an efficient manner.</p>
<p>Torch基于lua社区，其核心是易于使用的流行神经网络库和优化库，并且易于并行。</p>
<p>简单地介绍一下Lua: Because Torch is based on Lua and runs on Lua-JIT(just-in-time complier) which is fast.</p>
<ul>
<li><p>Lua is pretty close to javascript.</p>
</li>
<li><p>Only has one data structure built-in, a table: <code>{}</code>. Doubles as a hash-table and an array. 只有一种内置的数据结构</p>
</li>
<li><p>1-based indexing.</p>
<p>这里说明一下循环的写法，和python有些不一样： –代表注释</p>
<p>#(*) 代表长度</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for i&#x3D;1,#b do -- the # operator is the length operator in Lua</span><br><span class="line">    print(b[i]) </span><br><span class="line">end</span><br></pre></td></tr></table></figure>

<p>关于torch如何构造张量Tensor</p>
]]></content>
      <categories>
        <category>Torch</category>
      </categories>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/03/19/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
</search>
